{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import tweepy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):\n",
    "    \n",
    "    #create authentication for accessing Twitter\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    #initialize Tweepy API\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #get the name of the spreadsheet we will write to\n",
    "    fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag_phrase))\n",
    "\n",
    "    #open the spreadsheet we will write to\n",
    "    with open('%s.csv' % (fname), 'w',encoding=\"utf-8\") as file:\n",
    "\n",
    "        w = csv.writer(file)\n",
    "\n",
    "        #write header row to spreadsheet\n",
    "        w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])\n",
    "\n",
    "        #for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
    "        for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \\\n",
    "                                   lang=\"en\", tweet_mode='extended').items(100):\n",
    "            w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtag Phrase #flatearthers\n"
     ]
    }
   ],
   "source": [
    "consumer_key = 'x3yguSN30cfAefLBvBfi8VAh3'\n",
    "consumer_secret = 'dNNZyD56IE6nXdxIcf6fgdFoDHQko0qK9iRHL9fLpdurG4Ejj6'\n",
    "access_token = '1039440901792251904-5qy8WlPuJ2izG2uMpTS3zzlQ1P0H6Q'\n",
    "access_token_secret = 'CULwd5uXcS2N3iNSG16VHFRzRcQisEefiAM1sqYdaCl2x'\n",
    "    \n",
    "hashtag_phrase = input('Hashtag Phrase ')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words= set(stopwords.words('english'))\n",
    "    return([token.lower() for token in text if token not in stop_words])\n",
    "\n",
    "def stem_words(text):\n",
    "    stemmer= WordNetLemmatizer()\n",
    "    return([stemmer.lemmatize(token) for token in text])\n",
    "\n",
    "def stem_words_more(text):\n",
    "    stemmer=PorterStemmer()\n",
    "    return ([stemmer.stem(token) for token in text])\n",
    "\n",
    "def remove_puncts(text):\n",
    "    puncts= \"~`!@#€$%^&*()_-+={[}]|\\\\:;'<,>.?/\\''\"\n",
    "    return ([char for char in text if char not in puncts])\n",
    "\n",
    "def clean_data(input_list):\n",
    "    return_list=[]\n",
    "    for li in input_list:\n",
    "        return_list.append(stem_words(remove_puncts(remove_stop_words(tokenize(li)))))\n",
    "    return return_list\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweeter</th>\n",
       "      <th>retweet count</th>\n",
       "      <th>liked count</th>\n",
       "      <th>language</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>polarity</th>\n",
       "      <th>Postive/Neg</th>\n",
       "      <th>Sensitive</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@bulkevans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>@MattBerch87 @dmarble1 Flat Earthers hate debates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@ShootaFairOne</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>People want a reality show where flat earthers...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@politicians_sux</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>@StitchASvGHeart @candybossinit @realDonaldTru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@RedOphiuchus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>-2</td>\n",
       "      <td>False</td>\n",
       "      <td>@MindfulCopper @VesuviaAdelia @insidehighered ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@StitchASvGHeart</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>@politicians_sux @candybossinit @realDonaldTru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>@CoachDPenrod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>negative</td>\n",
       "      <td>-2</td>\n",
       "      <td>False</td>\n",
       "      <td>Television show idea: a reality show where fla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>@keith_wentworth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>joy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-2</td>\n",
       "      <td>False</td>\n",
       "      <td>@QuietlyRiot @_Gravity_Man @Itsjustanillus @MA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>@queso_the_rogue</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>negative</td>\n",
       "      <td>-3</td>\n",
       "      <td>False</td>\n",
       "      <td>@tsnurds Considering how many times flat earth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>@sars_cov</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>positive</td>\n",
       "      <td>-2</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @cultofshinees: explain this flat earthers ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>@RealNoss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>negative</td>\n",
       "      <td>-3</td>\n",
       "      <td>False</td>\n",
       "      <td>We need to load all the flat earthers onto a s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Tweeter   retweet count  liked count language  Emotion  polarity  \\\n",
       "0        @bulkevans              0            0       en    anger  negative   \n",
       "1    @ShootaFairOne              0            0       en  unknown  positive   \n",
       "2  @politicians_sux              0            0       en     fear  negative   \n",
       "3     @RedOphiuchus              0            0       en     fear  negative   \n",
       "4  @StitchASvGHeart              0            1       en  unknown  positive   \n",
       "5     @CoachDPenrod              0            0       en  unknown  negative   \n",
       "6  @keith_wentworth              0            0       en      joy   neutral   \n",
       "7  @queso_the_rogue              0            0       en  unknown  negative   \n",
       "8         @sars_cov              1            0       en  unknown  positive   \n",
       "9         @RealNoss              0            0       en  unknown  negative   \n",
       "\n",
       "   Postive/Neg  Sensitive                                                text  \\\n",
       "0           -1       False  @MattBerch87 @dmarble1 Flat Earthers hate debates   \n",
       "1            0       False  People want a reality show where flat earthers...   \n",
       "2           -1       False  @StitchASvGHeart @candybossinit @realDonaldTru...   \n",
       "3           -2       False  @MindfulCopper @VesuviaAdelia @insidehighered ...   \n",
       "4           -1       False  @politicians_sux @candybossinit @realDonaldTru...   \n",
       "5           -2       False  Television show idea: a reality show where fla...   \n",
       "6           -2       False  @QuietlyRiot @_Gravity_Man @Itsjustanillus @MA...   \n",
       "7           -3       False  @tsnurds Considering how many times flat earth...   \n",
       "8           -2       False  RT @cultofshinees: explain this flat earthers ...   \n",
       "9           -3       False  We need to load all the flat earthers onto a s...   \n",
       "\n",
       "  Unnamed: 9  Unnamed: 10  \n",
       "0        NaN          NaN  \n",
       "1        NaN          0.0  \n",
       "2        NaN          NaN  \n",
       "3        NaN          NaN  \n",
       "4        NaN          NaN  \n",
       "5        NaN          NaN  \n",
       "6        NaN          NaN  \n",
       "7        NaN          NaN  \n",
       "8        NaN          NaN  \n",
       "9        NaN          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/jscul/Desktop/Advanced machine learning/flatearthers.csv')\n",
    "df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweeter            0\n",
       "retweet count      0\n",
       "liked count        0\n",
       "language           0\n",
       "Emotion            0\n",
       "polarity           0\n",
       "Postive/Neg        0\n",
       "Sensitive          0\n",
       "text               0\n",
       "Unnamed: 9       881\n",
       "Unnamed: 10      885\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values:\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown     628\n",
       "joy         168\n",
       "sadness      28\n",
       "anger        28\n",
       "surprise     20\n",
       "fear         12\n",
       "disgust       2\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    542\n",
       "negative    248\n",
       "neutral      96\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt', 'mattishellafat', 'bruh', 'earth', 'isnt', 'flat', 'foot', 'straight', 'i', 'mean', 'year', 'would', 'evolved', 'curved', 'fee�']\n"
     ]
    }
   ],
   "source": [
    "X = df['text']\n",
    "y = df['Emotion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train = clean_data(X_train)\n",
    "X_test = clean_data(X_test)\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.005, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word',tokenizer=dummy,preprocessor=dummy,token_pattern=None)\n",
    "\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "\n",
    "model= MultinomialNB(alpha=0.005)\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   0   1   0   0   2]\n",
      " [  0   0   0   0   0   2]\n",
      " [  1   0  21   0   1  19]\n",
      " [  0   0   4   1   1   5]\n",
      " [  0   0   0   0   3   2]\n",
      " [  2   1   5   0   0 148]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.50      0.50      0.50         6\n",
      "        fear       0.00      0.00      0.00         2\n",
      "         joy       0.68      0.50      0.58        42\n",
      "     sadness       1.00      0.09      0.17        11\n",
      "    surprise       0.60      0.60      0.60         5\n",
      "     unknown       0.83      0.95      0.89       156\n",
      "\n",
      "    accuracy                           0.79       222\n",
      "   macro avg       0.60      0.44      0.45       222\n",
      "weighted avg       0.79      0.79      0.77       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7927927927927928\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt', 'mattishellafat', 'bruh', 'earth', 'isnt', 'flat', 'foot', 'straight', 'i', 'mean', 'year', 'would', 'evolved', 'curved', 'fee�']\n"
     ]
    }
   ],
   "source": [
    "X = df['text']\n",
    "y = df['polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train = clean_data(X_train)\n",
    "X_test = clean_data(X_test)\n",
    "\n",
    "print(X_train[0])\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word',tokenizer=dummy,preprocessor=dummy,token_pattern=None)\n",
    "\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "\n",
    "model= MultinomialNB(alpha=0.005)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 52   3  10]\n",
      " [  8   4   7]\n",
      " [ 12   8 118]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.80      0.76        65\n",
      "     neutral       0.27      0.21      0.24        19\n",
      "    positive       0.87      0.86      0.86       138\n",
      "\n",
      "    accuracy                           0.78       222\n",
      "   macro avg       0.62      0.62      0.62       222\n",
      "weighted avg       0.78      0.78      0.78       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gamestop crisis analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweeter</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Liked</th>\n",
       "      <th>retweet count</th>\n",
       "      <th>Language</th>\n",
       "      <th>sensitive</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@StonksDoctor</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>Hey @chamath I hear @GameStop and @ryancohen a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@BillLam7718</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>@Silverchiquita Instead of spending your last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@Cito_da_gunman</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>Well I have my covid vaccine 1st shot appointm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@shiftdeletenet</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tr</td>\n",
       "      <td>False</td>\n",
       "      <td>Son zamanlarda ciddi bir de?er kayb? ya?ayan o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@PyreSama</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>@DereckSaurusRex And that's one of the many re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>@SwingVoterz</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>LMAO! This is awesome Michael Bolton - Break U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>@phendrome</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1501</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @ConanOBrien: Okay guys I finally caved and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>@JohnLothian</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>ESMA Chair Steven Maijoor Delivers Statement O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>@sudeep1110</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>Started using @withopal last week and my phone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>@ThaMaggle</td>\n",
       "      <td>Positive</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @GamerSephiroth: is the gamestop in midgar ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Tweeter  Polarity  Liked  retweet count Language  sensitive  \\\n",
       "0    @StonksDoctor  Positive      0              0       en      False   \n",
       "1     @BillLam7718  Positive      0              0       en      False   \n",
       "2  @Cito_da_gunman  Positive      1              0       en      False   \n",
       "3  @shiftdeletenet  Positive      0              1       tr      False   \n",
       "4        @PyreSama   Neutral      0              0       en      False   \n",
       "5     @SwingVoterz  Positive      0              0       en      False   \n",
       "6       @phendrome  Positive   1501              0       en      False   \n",
       "7     @JohnLothian  Positive      0              0       en      False   \n",
       "8      @sudeep1110  Positive      0              0       en      False   \n",
       "9       @ThaMaggle  Positive    148              0       en      False   \n",
       "\n",
       "                                                Text  \n",
       "0  Hey @chamath I hear @GameStop and @ryancohen a...  \n",
       "1  @Silverchiquita Instead of spending your last ...  \n",
       "2  Well I have my covid vaccine 1st shot appointm...  \n",
       "3  Son zamanlarda ciddi bir de?er kayb? ya?ayan o...  \n",
       "4  @DereckSaurusRex And that's one of the many re...  \n",
       "5  LMAO! This is awesome Michael Bolton - Break U...  \n",
       "6  RT @ConanOBrien: Okay guys I finally caved and...  \n",
       "7  ESMA Chair Steven Maijoor Delivers Statement O...  \n",
       "8  Started using @withopal last week and my phone...  \n",
       "9  RT @GamerSephiroth: is the gamestop in midgar ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('C:/Users/jscul/Desktop/Advanced machine learning/gamestop.csv',encoding='latin1')\n",
    "df1.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    669\n",
       "Neutral     112\n",
       "Negative     18\n",
       "Name: Polarity, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt', 'appabend451', 'company', 'abuse', 'woman', 'that', \"'s\", 'horrible', 'support', 'woman', '``', 'okay', '``', 'tell', 'stop', '``', 'did', \"n't\", 'work', 'beg', 'sole', 'fema']\n"
     ]
    }
   ],
   "source": [
    "X = df1['Text']\n",
    "y = df1['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train = clean_data(X_train)\n",
    "X_test = clean_data(X_test)\n",
    "\n",
    "print(X_train[0])\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word',tokenizer=dummy,preprocessor=dummy,token_pattern=None)\n",
    "\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "\n",
    "model= MultinomialNB(alpha=0.005)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   3]\n",
      " [  1  14  11]\n",
      " [  3   9 159]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         3\n",
      "     Neutral       0.61      0.54      0.57        26\n",
      "    Positive       0.92      0.93      0.92       171\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.51      0.49      0.50       200\n",
      "weighted avg       0.86      0.86      0.86       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jscul\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.425, 'neu': 0.575, 'pos': 0.0, 'compound': -0.5719}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "df['polarity'].value_counts()\n",
    "df.iloc[0][8]\n",
    "\n",
    "sid.polarity_scores(df.iloc[0][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pos= []\n",
    "score_neu= []\n",
    "score_neg= []\n",
    "for i in range(0,df.shape[0]):\n",
    "    score = sid.polarity_scores(df.iloc[i][8])\n",
    "    score1= score['pos']\n",
    "    score_pos.append(score1)\n",
    "    \n",
    "    score2= score['neu']\n",
    "    score_neu.append(score2)\n",
    "    \n",
    "    score3= score['neg']\n",
    "    score_neg.append(score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['positive_score']=score_pos\n",
    "df['neutral_score']=score_neu\n",
    "df['negative_score']=score_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweeter</th>\n",
       "      <th>retweet count</th>\n",
       "      <th>liked count</th>\n",
       "      <th>language</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>polarity</th>\n",
       "      <th>Postive/Neg</th>\n",
       "      <th>Sensitive</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>negative_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@bulkevans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>@MattBerch87 @dmarble1 Flat Earthers hate debates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@ShootaFairOne</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>People want a reality show where flat earthers...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@politicians_sux</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>@StitchASvGHeart @candybossinit @realDonaldTru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@RedOphiuchus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>-2</td>\n",
       "      <td>False</td>\n",
       "      <td>@MindfulCopper @VesuviaAdelia @insidehighered ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@StitchASvGHeart</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>@politicians_sux @candybossinit @realDonaldTru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Tweeter   retweet count  liked count language  Emotion  polarity  \\\n",
       "0        @bulkevans              0            0       en    anger  negative   \n",
       "1    @ShootaFairOne              0            0       en  unknown  positive   \n",
       "2  @politicians_sux              0            0       en     fear  negative   \n",
       "3     @RedOphiuchus              0            0       en     fear  negative   \n",
       "4  @StitchASvGHeart              0            1       en  unknown  positive   \n",
       "\n",
       "   Postive/Neg  Sensitive                                                text  \\\n",
       "0           -1       False  @MattBerch87 @dmarble1 Flat Earthers hate debates   \n",
       "1            0       False  People want a reality show where flat earthers...   \n",
       "2           -1       False  @StitchASvGHeart @candybossinit @realDonaldTru...   \n",
       "3           -2       False  @MindfulCopper @VesuviaAdelia @insidehighered ...   \n",
       "4           -1       False  @politicians_sux @candybossinit @realDonaldTru...   \n",
       "\n",
       "  Unnamed: 9  Unnamed: 10  positive_score  neutral_score  negative_score  \n",
       "0        NaN          NaN           0.000          0.575           0.425  \n",
       "1        NaN          0.0           0.085          0.915           0.000  \n",
       "2        NaN          NaN           0.000          0.700           0.300  \n",
       "3        NaN          NaN           0.078          0.854           0.068  \n",
       "4        NaN          NaN           0.245          0.755           0.000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos score:  0.08506320541760727\n",
      "neu score:  0.868602708803614\n",
      "neg score:  0.046311512415349886\n"
     ]
    }
   ],
   "source": [
    "print('pos score: ',df['positive_score'].mean())\n",
    "print('neu score: ',df['neutral_score'].mean())\n",
    "print('neg score: ',df['negative_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos score:  0.0\n",
      "neu score:  0.899\n",
      "neg score:  0.0\n"
     ]
    }
   ],
   "source": [
    "print('pos score: ',df['positive_score'].median())\n",
    "print('neu score: ',df['neutral_score'].median())\n",
    "print('neg score: ',df['negative_score'].median())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
